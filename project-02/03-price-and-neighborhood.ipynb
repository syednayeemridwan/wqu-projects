{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>Predicting Price with Neighborhood</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Wrangle Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Masked dataset for specific category\n",
    "- Outlier free dataset\n",
    "- Dataset where a column contains specific string value (Masked)\n",
    "- Single column expanded to multiple columns\n",
    "- Dropped duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wrangle(filepath):\n",
    "#     # Read CSV file\n",
    "#     df = pd.read_csv(filepath)\n",
    "\n",
    "#     # Subset data: Apartments in \"Capital Federal\", less than 400,000\n",
    "#     mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
    "#     mask_apt = df[\"property_type\"] == \"apartment\"\n",
    "#     mask_price = df[\"price_aprox_usd\"] < 400_000\n",
    "#     df = df[mask_ba & mask_apt & mask_price]\n",
    "\n",
    "#     # Subset data: Remove outliers for \"surface_covered_in_m2\"\n",
    "#     low, high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n",
    "#     mask_area = df[\"surface_covered_in_m2\"].between(low, high)\n",
    "#     df = df[mask_area]\n",
    "\n",
    "#     # Split \"lat-lon\" column\n",
    "#     df[[\"lat\", \"lon\"]] = df[\"lat-lon\"].str.split(\",\", expand=True).astype(float)\n",
    "#     df.drop(columns=\"lat-lon\", inplace=True)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take all files and Concatenate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ignore index while concatenating / stacking multiple dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob(\"data/buenos-aires-real-estate-*.csv\")\n",
    "\n",
    "# frames = []\n",
    "\n",
    "# for file in files:\n",
    "#     df = wrangle(file)\n",
    "#     frames.append(df)\n",
    "\n",
    "# print(len(frames))\n",
    "# print(type(frames[0]))\n",
    "\n",
    "# df = pd.concat(frames, ignore_index = True)\n",
    "# print(df.shape)\n",
    "# print(df.info())\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Wrangle Function to make specific column from another column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a splitted portion from a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.columns)\n",
    "# def wrangle(filepath):\n",
    "#     # Read CSV file\n",
    "#     df = pd.read_csv(filepath)\n",
    "\n",
    "#     # Subset data: Apartments in \"Capital Federal\", less than 400,000\n",
    "#     mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
    "#     mask_apt = df[\"property_type\"] == \"apartment\"\n",
    "#     mask_price = df[\"price_aprox_usd\"] < 400_000\n",
    "#     df = df[mask_ba & mask_apt & mask_price]\n",
    "\n",
    "#     # Subset data: Remove outliers for \"surface_covered_in_m2\"\n",
    "#     low, high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n",
    "#     mask_area = df[\"surface_covered_in_m2\"].between(low, high)\n",
    "#     df = df[mask_area]\n",
    "\n",
    "#     # Split \"lat-lon\" column\n",
    "#     df[[\"lat\", \"lon\"]] = df[\"lat-lon\"].str.split(\",\", expand=True).astype(float)\n",
    "#     df.drop(columns=\"lat-lon\", inplace=True)\n",
    "\n",
    "#     df[\"neighborhood\"] = df[\"place_with_parent_names\"].str.split(\"|\", expand = True)[3]\n",
    "#     df.drop(columns = [\"place_with_parent_names\"], inplace = True)\n",
    "\n",
    "#     return df\n",
    "\n",
    "# frames = []\n",
    "\n",
    "# for file in files:\n",
    "#     df = wrangle(file)\n",
    "#     frames.append(df)\n",
    "# df = pd.concat(frames, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Training and Target Features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features represent dataframe\n",
    "- Target represents a single series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = \"price_aprox_usd\"\n",
    "# features = [\"neighborhood\"]\n",
    "# y_train = df[target]\n",
    "# X_train = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Y for Baseline Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_mean = y_train.mean()\n",
    "# y_pred_baseline = [y_mean] * len(y_train)\n",
    "# print(\"Mean apt price:\", y_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baseline Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Baseline MAE:\", mean_absolute_error(y_train, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform categorical variables in numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.head())\n",
    "# ohe = OneHotEncoder(use_cat_names=True)\n",
    "# ohe.fit(X_train)\n",
    "# XT_train = ohe.transform(X_train)\n",
    "# print(XT_train.shape)\n",
    "# XT_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Model Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_pipeline(\n",
    "#     OneHotEncoder(use_cat_names=True),\n",
    "#     LinearRegression()\n",
    "# )\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Y for New Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_training = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae_training = mean_absolute_error(y_train, y_pred_training)\n",
    "# print(\"Training MAE:\", round(mae_training, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a series out of predicted Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = pd.read_csv(\"data/buenos-aires-test-features.csv\")[features]\n",
    "# y_pred_test = pd.Series(model.predict(X_test))\n",
    "# y_pred_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Intercept and Co-efficients and generate equations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept = model.named_steps[\"linearregression\"].intercept_\n",
    "# coefficients = model.named_steps[\"linearregression\"].coef_\n",
    "# print(\"coefficients len:\", len(coefficients))\n",
    "# print(coefficients[:5])  # First five coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Works for categorical data and one-hot encoded set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = model.named_steps[\"onehotencoder\"].get_feature_names()\n",
    "# print(\"features len:\", len(feature_names))\n",
    "# print(feature_names[:5])  # First five feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take the co-efficients of the model\n",
    "- Make the co-efficients into series and index them with feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.Series(coefficients, index = feature_names)\n",
    "# feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"price = {intercept.round(2)}\")\n",
    "# for f, c in feat_imp.items():\n",
    "#     print(f\"+ ({round(c, 2)} * {f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make another Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_pipeline(\n",
    "#     OneHotEncoder(use_cat_names=True),\n",
    "#     Ridge()\n",
    "# )\n",
    "# model.fit(X_train,y_train)\n",
    "\n",
    "# intercept = model.named_steps[\"ridge\"].intercept_\n",
    "# coefficients = model.named_steps[\"ridge\"].coef_\n",
    "# print(\"coefficients len:\", len(coefficients))\n",
    "# print(coefficients[:5])  # First five coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = model.named_steps[\"onehotencoder\"].get_feature_names()\n",
    "# print(\"features len:\", len(feature_names))\n",
    "# print(feature_names[:5])  # First five feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take the co-efficients of the model\n",
    "- Make the co-efficients into series and index them with feature names\n",
    "- Happens naturally because co-efficients are associated with features in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.Series(coefficients, index = feature_names)\n",
    "# feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"price = {intercept.round(2)}\")\n",
    "# for f, c in feat_imp.items():\n",
    "#     print(f\"+ ({round(c, 2)} * {f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort the series\n",
    "- Remember to sort with absolute values (since importance can be represented in both positive and negative)\n",
    "- Plot them in horizontal bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp.sort_values(key=abs).tail(15).plot(kind = \"barh\")\n",
    "# plt.xlabel(\"Importance [USD]\")\n",
    "# plt.ylabel(\"Feature\")\n",
    "# plt.title(\"Feature Importance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
